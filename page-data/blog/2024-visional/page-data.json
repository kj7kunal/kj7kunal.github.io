{"componentChunkName":"component---src-templates-blog-post-jsx","path":"/blog/2024-visional/","result":{"data":{"site":{"siteMetadata":{"name":"Kunal Jain","title":"Kunal Jain | Machine Learning Engineer","description":"Machine Learning Engineer currently in Tokyo, Japan","about":"I'm a Machine Learning Engineer passionate about working in challenging and high-impact environments, and building automation pipelines that help save human time and effort. I love investigating new cutting-edge technologies and spending caffeinated lofi evenings implementing them in my personal projects. In my free time, I like to go long-distance running, visit coffee shops or learn the piano!","author":"kj7kunal","github":"https://github.com/kj7kunal","linkedin":"https://www.linkedin.com/in/kj7kunal","resume":"https://tinyurl.com/kunaljainresume","mail":"kjkunal7996@gmail.com"}},"markdownRemark":{"id":"799d1476-9acb-508d-b46f-b2bb334b275b","excerpt":"Five years ago, I embarked on my journey at Visional Inc.,\nas a fresh graduate eager to contribute to the AI and Machine Learning landscape in Tokyo, Japan…","html":"<p>Five years ago, I embarked on my journey at <a href=\"https://www.visional.inc/ja/index.html\">Visional Inc.</a>,\nas a fresh graduate eager to contribute to the AI and Machine Learning landscape in Tokyo, Japan.\nThree years ago, I penned my <a href=\"/blog/2021-visional\">2-Year milestone recap</a> that I had documented\nearlier and I believe that I have grown exponentially since then. At the time, I was excited about\nthe projects I had worked on, the growth I had experienced, and the challenges I had overcome.</p>\n<p>Now, as I stand at the cusp of my fifth anniversary, it’s a good time to reflect on the evolution\nof my role, my achievements, and the exciting challenges that have shaped me into the engineer I am today.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n<h2>Contents</h2>\n<ul>\n<li><a href=\"#revisiting\">Revisiting My Foundations</a>\n<ol>\n<li><a href=\"#manager\">A New Manager: Better communication</a></li>\n<li><a href=\"#okrs\">OKRs: Linking Personal and Professional Growth</a></li>\n<li><a href=\"#learning\">Continuous “Deep” Learning</a></li>\n<li><a href=\"#tools\">Tools for Enhanced Productivity</a></li>\n</ol>\n</li>\n<li><a href=\"#projects\">My Projects</a>\n<ol>\n<li><a href=\"#p1\">Resume Generation (Multiple Versions)</a></li>\n<li><a href=\"#p2\">AI MLOps: Feature Store PoC</a></li>\n<li><a href=\"#p3\">Resume LLM Fine-tuning (R&#x26;D Project)</a></li>\n<li><a href=\"#p4\">Financial Document OCR System (Improvements)</a></li>\n</ol>\n</li>\n<li><a href=\"#company\">About Visional</a></li>\n<li><a href=\"#conclusion\">The Road Ahead</a></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n<h2 id=\"revisiting\">Revisiting My Foundations</h2>\n<p>When I was writing my <a href=\"/blog/2021-visional\">2-Year recap blog</a>, I was still finding my\nfooting in the world of Machine Learning, juggling between different roles as a\nData Scientist, ML Engineer, and Research Scientist. I was focused on delivering value\nthrough the projects I worked on, such as the Financial Document OCR System and research\nprojects like Employee Slack Analytics or Japanese Handwritten OCR research. These\nprojects were critical in building my technical foundation, allowing me to dive deep\ninto the practical aspects of ML workflows.</p>\n<p>As I transitioned into the next phase of my career, I began to realize the importance\nof not just being an effective contributor but also taking on leadership roles within\nprojects, especially in shaping their direction and execution. This leads to what I\nbelieve were <strong>key developments in the last three years</strong>.</p>\n<h3 id=\"manager\">1. A New Manager: Better communication</h3>\n<p>One of the most significant changes in my professional life was hands-down my\nVietnamese team lead becoming my manager. This transition had a profound impact on\nhow I approached my work. Being able to directly converse in English with my manager,\nnot only about technical issues but also management-related concerns made me more\ncomfortable in my place within the team. Communication within the team became more\nseamless, and I found myself more involved in the early roadmapping phases of projects.</p>\n<p>A notable example was the <a href=\"#p1\">Resume Generation project</a>, a super\nimpactful project where I was able to contribute right from the brainstorming stage.\nThis involvement not only allowed me to secure projects more easily but also gave me\nthe confidence to push for innovative solutions to both technical and management\nrelated issues. I am truly grateful for having him as my manager for the past 3 years.</p>\n<h3 id=\"okrs\">2. OKRs: Linking Personal and Professional Growth</h3>\n<p>Another shift in my professional growth came from my adoption of personal OKRs\n(Objectives and Key Results), a practice inspired by Google’s approach, which\nI learned from reading the book <a href=\"https://www.google.co.jp/books/edition/_/VEtTDwAAQBAJ\">Measure What Matters by John Doerr</a>. I believe that I had initially struggled with the company’s\nMBO (Management by Objectives) system, not knowing how they would link back to\nthe broader company objectives OR my own career goals. OKRs are designed to\nbe transparent and cascaded through organization levels.</p>\n<p>Adopting such a practice for my personal goals taught me how I could link my work with\nmy career goals, focusing on <em>outcomes rather than output</em>. This personal system kept\nme on track, ensuring that my work was always purposeful and aligned with both my\nprofessional growth and the company’s vision.</p>\n<h3 id=\"learning\">3. Continuous \"Deep\" Learning</h3>\n<p>Reading <a href=\"https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/\">Designing Machine Learning Systems by Chip Huyen</a> was a game-changer for me. The book\nprovided me with a comprehensive understanding of ML systems, evolving my notion of\nmachine learning beyond just developing an <em>End-to-End Pipeline</em>, to a holistic\n<em>Machine Learning Life Cycle</em> - from data collection to deployment. Learning best practices\nin designing scalable and reliable ML systems is crucial for moving from experiments/internal\nprojects to production-grade applications.</p>\n<p>The book particularly emphasized the significance of MLOps — a field that was coincidentally\ngaining momentum within our team thanks to a new colleague who moved to our company from AWS\nas an MLOps Architect. I have learned a lot from our conversations on Teal Organizations,\nTeam Topologies, frameworks for Logical Thinking, and in general MLOps. Armed with this new\nknowledge, we proposed a <a href=\"#p2\">re-architecture of our AI MLOps</a>, focusing on scaling\nour infrastructure and improving the reliability of our models in production. This initiative\nwas a key milestone in my journey, marking the transition from being a contributor to a\nthought leader in my team.</p>\n<h3 id=\"tools\">4. Tools for Enhanced Productivity</h3>\n<p>When a person with ADHD who has always been an academic achiever finds themselves unable to change\njobs, be it due to fear of change, high standards or even emotional attachment, they begin to devise\npersonalized workflows to keep up with the increasing complexity of projects.</p>\n<p><strong>Google Meets’ closed captioning</strong> and the <strong>Google Translate browser extension</strong> allowed\nme to better understand in-person and virtual meetings, ensuring that I remained an active\nparticipant in all discussions, regardless of language barriers. The move from Confluence to\n<strong>Scrapbox</strong> as a documentation tool in our company, which is coupled with <strong>DeepL</strong> for\ntranslations, helped me bridge the language gap and contribute more effectively in Japanese.</p>\n<p>Outside the language barrier, <strong>Miro</strong> became indispensable for system architecture designs\nand big-picture mind maps, helping me and my team visualize and communicate complex ideas\neffortlessly. Tools like <strong>ChatGPT/Copilot</strong> for code improvement, debugging, and\ndocumentation significantly boosted my productivity.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n<h2 id=\"projects\">My Projects</h2>\nThe past three years have been transformative, owing to key projects which not only \ntested my technical skills but also pushed me to grow as a leader and innovator in \nthe ML space. I found myself going the extra mile, partly due to the demands of the \nproject and partly due to the passion and satisfaction I discovered while working on them.\n<p> </p>\n<h3 id=\"p1\">1. Resume Generation (Multiple Versions)</h3>\nThe Resume Generation project has been an ongoing effort, with several key milestones \nachieved over the last three years - even prior to the advent of ChatGPT. I can \nsummarize the changes brought by each version, and how they were built upon the previous version.\n<p align=\"center\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/134d61170aa28b8d1d65eb664e11bc2c/9888a/resume_generation.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 71.62162162162163%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe5SC2D/xAAXEAADAQAAAAAAAAAAAAAAAAAAEBEx/9oACAEBAAEFAlSGL//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABgQAAMBAQAAAAAAAAAAAAAAAAABESFR/9oACAEBAAE/IW4Urg0ZMq1PNEf/2gAMAwEAAgADAAAAEKAP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHBABAQEAAgMBAAAAAAAAAAAAAREAITFBUWGB/9oACAEBAAE/EATFh23i4YNLDvCF4fuInX0yyjbHlfeCE43/2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Resume Generation Project\" title=\"\" src=\"/static/134d61170aa28b8d1d65eb664e11bc2c/1c72d/resume_generation.jpg\" srcset=\"/static/134d61170aa28b8d1d65eb664e11bc2c/a80bd/resume_generation.jpg 148w,\n/static/134d61170aa28b8d1d65eb664e11bc2c/1c91a/resume_generation.jpg 295w,\n/static/134d61170aa28b8d1d65eb664e11bc2c/1c72d/resume_generation.jpg 590w,\n/static/134d61170aa28b8d1d65eb664e11bc2c/a8a14/resume_generation.jpg 885w,\n/static/134d61170aa28b8d1d65eb664e11bc2c/fbd2c/resume_generation.jpg 1180w,\n/static/134d61170aa28b8d1d65eb664e11bc2c/9888a/resume_generation.jpg 1198w\" sizes=\"(max-width: 590px) 100vw, 590px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</p>\n<h4><em>Version 0: Keyword Suggestion</em></h4>\n<p>The first and foremost AI assistance our platform could provide candidates in the\nregistration process was suggesting them relevant keywords to enhance their profiles.\nThis version used algorithms like tfidf and k-means clustering to recommend keywords\nwhich candidates could simply incorporate into their project descriptions, thereby\nincreasing their scout rates with recruiters. I joined the resume generation\nproject with this version already in production.</p>\n<h4><em>Version 1: Keyword Recommendation -> Sentence Recommendation</em></h4>\n<p>Building on the basics, we moved towards a more sophisticated approach: recommending\nsentences to candidates while they wrote their project descriptions. This version\nintroduced a two-step pipeline, each step trying to reduce the distance between inputs\nand outputs in an embedding space. I focussed mainly on the first component.</p>\n<p><strong>1. Keyword Recommendation</strong> [Resume text and categorical features] -> [Relevant keywords]</p>\n<blockquote>\n<p>Resume features were vectorized and concatenated to form a resume vector. Topic modeling using LDA was used to create an embedding model for resume-keyword similarity</p>\n</blockquote>\n<p><strong>2. Sentence Recommendation</strong> [User selected keywords] -> [Relevant next sentences]</p>\n<blockquote>\n<p>A BERT Semantic Textual Similarity (STS) model was used to find possible next sentences similar to keywords selected in the previous step</p>\n</blockquote>\n<h4><em>Version 2: Keyword Recommendation -> Text Generation</em></h4>\n<p>ChatGPT was released to the world in the beginning of Dec 2022. Within days, our senior\nengineers had built a prototype with the <code class=\"language-text\">text-davinci-003</code> API, which led to rapid\ndevelopments post-New year. A large project team was formed, including frontend,\nbackend, ML, QA, legal, etc., and I found myself sitting beside my manager on the\nlargest Japanese round table in my life, and between listening hard to navigate\nfast-paced discussions and vaguely looking at my manager, I was trying to fit\ntogether context like pieces of a jigsaw. I made through it - somehow, and was set\nto release the first version of the new ML system within 2 months, the backbone\nto what became one of the most intense, yet rewarding, phases of my career so far.</p>\n<p>Those two months of development felt like a throwback to my university days,\nfilled with late hours and deep focus. But that’s a story for another time—let’s\nstick to the technical milestones. Buy me a coffee to hear more, I guess!</p>\n<p><strong>Keyword Recommendation: Improvements</strong></p>\n<blockquote>\n<p>The embedding model for resume-keyword similarity was iteratively improved as follows:</p>\n<ul>\n<li>Resume features were transformed into BERT input strings. Semantic Textual Similarity was used to train resume-keyword similarities</li>\n<li>Reranking was introduced according to keyword selection rate and search popularity</li>\n</ul>\n</blockquote>\n<p><strong>Text Generation: ML System Design</strong></p>\n<blockquote>\n<p>We transitioned to a microservices-based architecture, enabling independent handling of different components in the resume generation pipeline. Key features included:</p>\n<ul>\n<li>Message-forwarding and queuing via AWS SQS and DynamoDB</li>\n<li>Multithreading capabilities, processing up to 60 Generation RPM, within OpenAI’s rate limits</li>\n<li>A robust internal mapping system to manage OpenAI’s success/error responses</li>\n<li>Moderation layers to act as guardrails to reinforce the <code class=\"language-text\">harmless</code> in the <a href=\"https://arxiv.org/abs/2112.00861\">3Hs for LLMs</a></li>\n</ul>\n</blockquote>\n<p align=\"center\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/b456dea9e21ae83b789ed79b062b55dc/344cf/datadash.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 57.432432432432435%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACS0lEQVR42l2SS2vUYBSG87tcuHMj/gRx50bwB/gXFESw7lQUrVQoUrvwAkUX1oVYFNvaltrpxc5Mp2mTL5dJvtv58vomGVAMnMmQc87znlukq8o3IUBEcJob7CcOp6UgngomZYCqLCbFGIPsAPvFIcbVCUo3hXEO3nsE5vJpGv548XVkq9ofD8dQShHiMYg1jlKDY2X5duGsqGV5b1mebj6T+a3nMr+9IG8G7ySplKCBECpkevRPEdXaiKWa46ey8qiEik1vjXgxxjiW74z2LtNwTHJkOJHgKl3TB/dN7bp7ey/846PXOgr0SMs+W8LSpyEerKwDKkb7Tfp2kFDs2m7ApZ8NFlVfSmCTJ8OascD9jZe48OEqrny+iaj1lZzFk63baEyK9S9z2Bm86pKs9J3cGQG3DgNOtMfFDc6q6aE5S87HFmvDbTzaXsTCr7cEBorRubqyirnvMQZfH0JXa12C72vHxxy4vANc3wduHMymxQHGBG7+LmB930nDqiNjHZFUsxqL4wJnI90FhzCzbn8N3p873D3SKLrkpttrWhisHxQYJRWMd9DW+khlOcq8gK458XwfteFJGAtdlhDn+kq5qBDa9qUTaP6zELomGSdpdJ4qlDwZZx0mk01k2YggQZ2m8Mb0C+ByNEWmWsPO7s/xbW37X9q190BPYKIylFkGx4QkboExPG+oztRfII++jSvYiSO0hTnGVFUF24pozYsUGK1nQJplcjz5gSQhkMo1Rf6tMOVopnkOTWsFuiugP2d3hcoaz4JcrdM/OSpAUC9bUVUAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"First Datadog Dashboard\" title=\"\" src=\"/static/b456dea9e21ae83b789ed79b062b55dc/fcda8/datadash.png\" srcset=\"/static/b456dea9e21ae83b789ed79b062b55dc/12f09/datadash.png 148w,\n/static/b456dea9e21ae83b789ed79b062b55dc/e4a3f/datadash.png 295w,\n/static/b456dea9e21ae83b789ed79b062b55dc/fcda8/datadash.png 590w,\n/static/b456dea9e21ae83b789ed79b062b55dc/efc66/datadash.png 885w,\n/static/b456dea9e21ae83b789ed79b062b55dc/c83ae/datadash.png 1180w,\n/static/b456dea9e21ae83b789ed79b062b55dc/344cf/datadash.png 2643w\" sizes=\"(max-width: 590px) 100vw, 590px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</p>\n<p>The system required <strong>high cross-team collaboration</strong> with product backend, frontend\nand QA teams. I took the initiative to create the <strong>first Datadog dashboard for the AI ​​team</strong>,\nmaking it easy to share weekly insights, respond to incidents, improving the flow of communication on the AI side.</p>\n<p><strong>The business impact? A <a href=\"https://www.bizreach.co.jp/pressroom/pressrelease/2023/070601.html\">40% improvement in our scout-reception KPIs</a>!</strong></p>\n<p>Oh, and the team received the <strong>Best Project Team Award</strong> at the BizReach Awards 2023.\nLook at the size of the team! The memories of that project are still fresh, and the\naward ceremony—a reminder of how collective effort and innovation can lead to extraordinary results.</p>\n<p align=\"center\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/ca0be235ba75eca8c329a97f2ca127cf/18d85/award_team.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60.13513513513513%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAADGElEQVR42h2TyW4bRxCG5+BApiRKpEVSXMJ1SIrrcBlxhssM980UJSqyuFlSKEuCYSswrMAOEDuIjCALkKuDnHzKLU+Qcx4hb/Sl4QYKXUB3/dX1VbXkCcuEkll80STZaouM0cOXreLKt3FkDJyxPC45izOq4IpmCeZqPJJzbDj9bLt8hJUSSr2HO5zAG9lDsru97AYjwqJE0ip7pTqhgolHqbGb0ngUzuCJKfiEucJJnCLQHohj98l4IklixTKxgo5XTuAJx5A2bHa2nG5sbj+uUIJgWheCDeRiG39KF68t446m8cZVvAmN7UAOWyAt7sbxJ/LIhSpyVvssvu30IFk2NlnfsuH0BvBHU7jlPKn2Kfu1KUbvOUl9hH9/gDV1xJfGBQ7tHEvua3ayfXyZKiFRSSip4vAF2RA60kOLhQcPLVTKOg2zjl5rcvjkGKN/SevghnJjgjZakVQbpI0xxvCE8njF48v31HsTuoMhSi4v4susW7eQvlhbw7JpJZVIERdWb7U5Gg1Qyw0WsxnN7pBas0urN+JsOWc2W1LrHIlkC1FFl3i6QKXepT+ZsbZpRxILfb+IWdEIRaKcz2fE95I8ORyQLxTIKApaURVJHnP/+oqa2UAvGxjlCgHBcS+V42DYx6i3eLC+jWS1O2iMnpLOFJETCiWjT6PToz865uJsxc9v3zAf1JgfHvDHh++5Xp7yyw8/8vG339F0ncXJIbPpnNPTBfYdJ5JHjIHen9MR/PbzRVrVCjm1TKGg8ev9T7y/+46mWSNf1Pnr45/89+8/fHj3jovpU1H+jL8/fWJ1fsZieYbL60Oy7ewSE/Onq0XikTCpqIzFaiMajtMU7PKqRqduEg0FkX3ezxiUnIpVNKBUyHN/+4JKIUNElnG4dpECoQi+QFDAVciVdNSqidnpC/B9zO6A4eSEqvBHk6/oj8dogqHR7lCtN8kJtsGITEQ0M6uKHyOSSfFEhmyxhG40qDZ79A4mTKZLFqsrlpc3XNy84PbuLdffvObZy1c8f3XH7bdvxNkVx4tzsV8zPplSa/eomE3+B2VEjH7mitVeAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Bizreach Awards\" title=\"\" src=\"/static/ca0be235ba75eca8c329a97f2ca127cf/fcda8/award_team.png\" srcset=\"/static/ca0be235ba75eca8c329a97f2ca127cf/12f09/award_team.png 148w,\n/static/ca0be235ba75eca8c329a97f2ca127cf/e4a3f/award_team.png 295w,\n/static/ca0be235ba75eca8c329a97f2ca127cf/fcda8/award_team.png 590w,\n/static/ca0be235ba75eca8c329a97f2ca127cf/efc66/award_team.png 885w,\n/static/ca0be235ba75eca8c329a97f2ca127cf/c83ae/award_team.png 1180w,\n/static/ca0be235ba75eca8c329a97f2ca127cf/18d85/award_team.png 2382w\" sizes=\"(max-width: 590px) 100vw, 590px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</p>\n<p>Almost a year has passed since then, and with the system architecture in place,\nthe focus shifted to optimizing performance:</p>\n<blockquote>\n<ul>\n<li>Explored various ML models to improve keyword recommendation metrics for better user experience</li>\n<li>Improved prompt templates across different job categories, guided by <a href=\"https://arxiv.org/html/2312.16171v1\">prompt engineering best practices</a></li>\n<li>Improved incident response, reducing time-to-detect (TTD) and time-to-mitigate (TTM) by adding more alerts and implementing redundancy measures, such as provider/region switching</li>\n<li>Redesigned the architecture to support multi-API integration, ensuring backward compatibility while introducing new features and enhanced prompts.</li>\n</ul>\n</blockquote>\n<p>The Resume Generation project has been one of the most impactful projects\nI’ve worked on, significantly contributing to the company’s core offerings and\ndemonstrating my ability to lead and deliver in complex, multi-phase projects.</p>\n<h3 id=\"p2\">2. AI MLOps: Feature Store PoC</h3>\n<p>As mentioned above I had started reading <a href=\"https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/\">Designing Machine Learning Systems by Chip Huyen</a>\nin the start of 2024. Learning about best practices in a holistic\n<em>Machine Learning Life Cycle</em> inspired me to connect more with our MLOps team.\nIn our discussions we identified a <a href=\"https://research.google/pubs/machine-learning-the-high-interest-credit-card-of-technical-debt/\">technical debt</a>\nin the form of overlapping data pipelines within a significant portion of\nour around 30 batch pipelines in production.</p>\n<p>As a young ML Engineer, I remember spending 2 weeks building a search ML pipeline\nfrom scratch that I later found out could have just been modified from another\nteam’s project that used the same data. I can say, I have always had a passion\nfor automation and standardization.  This need to standardize and centralize features\nacross multiple pipelines and projects resulted a proposal for the re-architecture\nof our AI MLOps systems, centered around developing AI Group’s first\nFeature Store as a proof-of-concept (PoC).</p>\n<blockquote>\n<p>Although it is still early in my MLOps journey, I strongly believe that Google\nhas set the standard in this space, and their documentation is a gold mine of\nlearning. They summarize <a href=\"https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning\">a Golden Path to MLOps</a>,\nwhich became my go-to resource for understanding how to incrementally build an\norganization’s MLOps capabilities across CI/CD/CT pipelines. It shows how\nhigher levels of automation could <strong>accelerate</strong> the ML lifecycle. Higher the\nlevel, higher the <strong>velocity</strong> of deploying new models given new data/implementations.</p>\n</blockquote>\n<blockquote>\n<p>It is worth noting that each organization takes a different path, but as\nmentioned in <a href=\"https://sistel.medium.com/the-mlops-engineer-vertical-first-horizontal-second-306fa7b7a80b\">Vertical First Horizontal Second</a>,\nachieving early vertical breakthroughs is critical. This approach involves\n“agile” deployment of vertical prototypes early in the development process\nto detect risks, iterate quickly, and align closer with production settings\nand stakeholders. However, at some point we do need to increase an\nML team’s breadth and move to horizontal splitting.</p>\n</blockquote>\n<p>While our journey towards MLOps maturity shares commonalities with\nGoogle’s levels, it is not a direct testament to Google’s MLOps level\ndefinitions.  Instead, it reflects <strong>our unique path</strong>, tailored to our\nspecific challenges, infrastructure, and business needs. By understanding where\nwe stand and the steps we’ve taken, we can better appreciate our progress\nand identify areas for further improvement. Here was my take on our starting point and destination:</p>\n<p align=\"center\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/34fd1d28ecd4cd6564a52693fa35eddf/a1e6a/mlops_maturity_levels.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 31.08108108108108%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABOklEQVR42i2QyXIbMQxE5/8/zcccU3a8xJE0moUcbuA2fIFUPnSRBBvoRk/Grpjjjot3QlLIii+JQ7KeZZjacaW5VOmla93PWHfB+Ssu3LBJcCKsUdhSYUr1wKedIyz4uDDfvtm9U2J6Dvy8OvaQnaP2S1owyRCLx4tjXTcVK4SSWWxiNokptE4eAzlPHvdQT8qA1Bo2hjGHis3Nvdnv/mt7Y2uiQh3fziei9poQmI/ILpVpV+3ZHlhdzWRtrk0/Ckep3Dc/Dn0ndKvSesyFz9XxsSfe98jHJvxVVzYWbibyiGeKffBn8byvD0J6kl7vnlVDk36Of1vESnUFejw7VoWuyfOy/eZV89yyoH/E3DQGdShqOZ6D8IP4g6T1DCOrG9GBogOzRmF05a0GQm98ycIlmwePEIQUMv8BxNrN9idsoEEAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"MLOps Maturity Levels\" title=\"\" src=\"/static/34fd1d28ecd4cd6564a52693fa35eddf/fcda8/mlops_maturity_levels.png\" srcset=\"/static/34fd1d28ecd4cd6564a52693fa35eddf/12f09/mlops_maturity_levels.png 148w,\n/static/34fd1d28ecd4cd6564a52693fa35eddf/e4a3f/mlops_maturity_levels.png 295w,\n/static/34fd1d28ecd4cd6564a52693fa35eddf/fcda8/mlops_maturity_levels.png 590w,\n/static/34fd1d28ecd4cd6564a52693fa35eddf/efc66/mlops_maturity_levels.png 885w,\n/static/34fd1d28ecd4cd6564a52693fa35eddf/c83ae/mlops_maturity_levels.png 1180w,\n/static/34fd1d28ecd4cd6564a52693fa35eddf/a1e6a/mlops_maturity_levels.png 3581w\" sizes=\"(max-width: 590px) 100vw, 590px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</p>\n<blockquote>\n<p>Once our MLOps vision reached a practical stage, we attended a 2-day\n<strong>Google MLOps Mini TAP (Tech Acceleration Program)</strong> at the Google Tokyo Office to\nrefine our MLOps direction using Google Cloud’s solutions. We decided to\nimplement the first PoC using <a href=\"https://cloud.google.com/vertex-ai/docs/featurestore\">Vertex AI</a>.</p>\n</blockquote>\n<p>For the Feature Store PoC, I led the design and implementation of the feature store schema,\nfocusing on decoupling the data and model pipelines for an existing low-impact score\nprediction project. This project had feature overlaps with others, making it the perfect\ncandidate for standardization. The process required a lot of self-study, but it\nultimately equipped me with a solid understanding of the core components:</p>\n<blockquote>\n<ol>\n<li><strong>Data Pipeline</strong>: Apache Beam, Google Dataflow (flex-templates)</li>\n<li><strong>Model Monitoring</strong>: Vertex AI Model Monitoring</li>\n<li><strong>Online Feature Serving</strong>: Vertex AI Feature Store</li>\n</ol>\n</blockquote>\n<blockquote>\n<p>Parallely, my colleague focussed on <strong>Model Training</strong>, <strong>Model Evaluation</strong> and\n<strong>Model registration</strong>. FWe later integrated everything into a coherent\nworkflow using <strong>Kubeflow Pipelines (kfp)</strong>.</p>\n</blockquote>\n<p>Looking back, this PoC was a major step forward for us. It wasn’t just about\nimplementing new technology—it was about laying the groundwork for future\nscalability and improving the overall velocity of our ML projects. There’s a lot to do next term!</p>\n<h3 id=\"p3\">3. Resume LLM Fine-tuning (R&D Project)</h3>\n<p>In an effort to stay at the cutting edge of the recent boom in AI and LLMs, I took\non the challenge for an R&#x26;D project focused on fine-tuning a Large Language Model (LLM)\nfor resume generation, building upon my work on the Resume Generation project.</p>\n<p>This project was particularly challenging as it involved working with vast amounts\nof unstructured text data and adapting a pre-trained LLM to our specific domain. The\nmain aim was to explore the feasibility of developing an in-house LLM to reduce the\ndependence on external models like ChatGPT. A secondary outcome was to establish a\nbaseline PoC for LLM fine-tuning within our AI Group.</p>\n<p align=\"center\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/94ce6d51443792ef9cfa255d0c17ba65/3fe40/llm_miro.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 15.54054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA+klEQVR42mPo7tbjPnzXvuHgHYf0/Tftcw/ccKjXc3XlZgACDbc7xrr+98p0A27lM/D/F7xxX1jjzDWtuqMXNHSOXlQPOXxeo8DCQoZz1zk7r1OPHXvbpxslMNQXagltP2E9aeshq6p9F2yKjt6xrwGaxfJ942yVHVMP75jZfv7/zPbTfy7MPFq78mJZ/Lyrlf+nnSmJmnq6ZPPUUyWvSjd08u6/YuNx4qHjxL55xvEMj8vUGz9Umx55X6F//F2psh8DFByeNt/ixeqVbf93Lin8tWN59ac1qypzVmx38Vy2Y1HA5oNm/it25/qt3t3jsXgxH0yPuLi4IgB0HnH3UmCrEQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Resume LLM Fine-tuning\" title=\"\" src=\"/static/94ce6d51443792ef9cfa255d0c17ba65/fcda8/llm_miro.png\" srcset=\"/static/94ce6d51443792ef9cfa255d0c17ba65/12f09/llm_miro.png 148w,\n/static/94ce6d51443792ef9cfa255d0c17ba65/e4a3f/llm_miro.png 295w,\n/static/94ce6d51443792ef9cfa255d0c17ba65/fcda8/llm_miro.png 590w,\n/static/94ce6d51443792ef9cfa255d0c17ba65/efc66/llm_miro.png 885w,\n/static/94ce6d51443792ef9cfa255d0c17ba65/c83ae/llm_miro.png 1180w,\n/static/94ce6d51443792ef9cfa255d0c17ba65/3fe40/llm_miro.png 2517w\" sizes=\"(max-width: 590px) 100vw, 590px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</p>\n<p>As the sole contributor to this R&#x26;D task, I approached the project with a flexible proposal and roadmap, which led to the following structured approach:</p>\n<blockquote>\n<ol>\n<li>Self-learning and Methodology review\n<ul>\n<li>Conducted an in-depth review of <a href=\"https://qiita.com/mshinoda88/items/fc562ec6a84f45e89e70#llm%E3%81%AEfine-tuning%E6%89%8B%E6%B3%95%E3%81%BE%E3%81%A8%E3%82%81\">LLM fine-tuning methods</a> such as LoRA and PEFT</li>\n<li>Surveyed various pre-trained and fine-tuned models in the <a href=\"https://huggingface.co/learn/nlp-course/chapter3/1?fw=pt\">HuggingFace documentation</a></li>\n<li>Completed the <a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7160184133703372800/\">Generative AI with Large Language Models</a> course offered by DeepLearning.AI and Amazon Web Services to enhance my understanding of these techniques</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"2\">\n<li>Data Engineering and training data curation\n<ul>\n<li>Data sampling ensuring high alignment with business KPIs along with diversity and representativeness</li>\n<li>Extracting features from candidate resumes using NLP techniques</li>\n<li>Structured these features into prompts with the <code class=\"language-text\">Alpaca format</code> for instruction fine-tuning (supervised)</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"3\">\n<li>Base model selection: <a href=\"https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-fast-instruct\">elyza/ELYZA-Japanese-Llama-2-7b-fast-instruct</a>\n<ul>\n<li>open-source 7B parameter model with Japanese language capabilities</li>\n<li>fine-tuned on Meta’s <a href=\"https://llama.meta.com/llama2/\">Llama2</a> Large Language Model</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"4\">\n<li>Fine-tuning Experiments\n<ul>\n<li>QLoRA (using bitsandbytes and PEFT) to optimize compute budget</li>\n<li>Tuning batch sizes to optimize memory and training time</li>\n<li>Filtering prompt lengths to reduce memory usage (irregular padding) and increase batch sizes</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n<blockquote>\n<ol start=\"5\">\n<li>LLMOps\n<ul>\n<li>Running large parametric TrainingJobs from small SageMaker notebook instances</li>\n<li>Logging results and metrics (eg. ROUGE score) to S3 for quality feedback from domain experts, crucial in refining the model and improving output quality</li>\n</ul>\n</li>\n</ol>\n</blockquote>\n<p>In the end, as expected, there was much room for improvement. It requires a lot more effort\nto achieve expected metrics and quality to beat a proprietary external LLM. Enhancing\ndata size and quality, tuning model parameters, implementing iterative evaluation with\nhuman feedback (RLHF) were some of the ways in which I could have refined performance.\nThe project sucessfully laid the groundwork for future LLM fine-tuning efforts within\nour AI Group, showcasing the potential for developing specialized in-house models\ntailored to our unique needs.</p>\n<h3 id=\"p4\">4. Financial Document OCR System Improvements</h3>\n<p>Building on the success of the <a href=\"/blog/2021-visional#p1\">initial Financial Document OCR system</a>,\nI led 2 major improvement phases that further enhanced the system’s accuracy and usability.</p>\n<p>Improvement 1:</p>\n<blockquote>\n<p>The first phase focused on improving the text recognition accuracy, particularly for\ndocuments with poor scan quality or complex layouts. I incorporated advanced image\npreprocessing techniques such as noise reduction, skew correction, and adaptive\nthresholding. The qualitative evaluation score passed for 90% of the test files\nas a result, increasing from around 85% last term. As an extra, the output format was\nchanged from XLS to XLSX for better compatibility.</p>\n</blockquote>\n<p>Improvement 2:</p>\n<blockquote>\n<p>The second phase aimed at expanding the support for 4 new types of documents. I\ndesigned image processing algorithms able to deal with tables with defined cell\nboundaries as well as processing wrapped text in such cells. The format detection\nlogic was updated to support both old and new algorithms.</p>\n</blockquote>\n<p>While I am aware that new and faster methods using multi-modal LLMs are now available, but at that time, these improvements had not only enhanced the system’s performance but also reduced the manual effort required in processing financial documents, leading to substantial time savings and increased productivity for the team. A benchmarking by the Succeed team proved the internal tool to be better than <a href=\"https://line-works.com/ai-product/ocr/\">Line Works OCR</a> tool in terms of data privacy, ease of use and specialized usecase.</p>\n<p align=\"center\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/a1bcd07a05bdf262fc28224f19e40278/37114/focr.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 45.27027027027027%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAABYklEQVR42k1Sy3KDMAzk/z8uJc0AoecEUoa3bTDYoGrlMVMu2JJ2tVo5cc7ReZx0HAft+06444z/tm3XHTncvfcc2yWW3u90u91oGEeq6orarqUEifM8Bbgsi4DiHSTeg8zRuloyZrnuB4u4M2FRFIRvnCauWSkBeOQObdtKou976R6UOLLbTq/XS3Jaa1JKCynyWZbT8/kUAUopbmgCodaGSQchmrhTGN3LH2rQDAQAzPMsMZCmaUplWQoO0wkhOoOkaRqy1sr55Ng6T6S7jjYGV++35ACwPBbI1W9D3zxynufSGOpRIwqHYRBC+NcxiSwFS+ACazeq68+lDkD4h3z6lfLYGZ8dGVaIZkn0CsXwIfikro1j9EiGsZCHRWgK/zByjBujg0IEAEARwGgSnwf86vvgr+VNo9a5sJSy/JEtx9ehWcil8P/7i38UYqvTNMuTwTluE0t5PB5C6LkeViH3B1lHtdyi/PVPAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"old image since I cannot share proprietary example\" title=\"\" src=\"/static/a1bcd07a05bdf262fc28224f19e40278/fcda8/focr.png\" srcset=\"/static/a1bcd07a05bdf262fc28224f19e40278/12f09/focr.png 148w,\n/static/a1bcd07a05bdf262fc28224f19e40278/e4a3f/focr.png 295w,\n/static/a1bcd07a05bdf262fc28224f19e40278/fcda8/focr.png 590w,\n/static/a1bcd07a05bdf262fc28224f19e40278/efc66/focr.png 885w,\n/static/a1bcd07a05bdf262fc28224f19e40278/c83ae/focr.png 1180w,\n/static/a1bcd07a05bdf262fc28224f19e40278/37114/focr.png 2300w\" sizes=\"(max-width: 590px) 100vw, 590px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n<h2 id=\"company\">About Visional</h2>\n<p align=\"center\">\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/7dcdbba96ae2789a28d90c974627ddb4/3ec44/visional_cafe.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 47.972972972972975%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAIEAwX/xAAWAQEBAQAAAAAAAAAAAAAAAAADAQL/2gAMAwEAAhADEAAAAdWoUlhOoXP/xAAaEAEAAwADAAAAAAAAAAAAAAABAgMRABMx/9oACAEBAAEFAuyYyscm26huHDz/xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAwEBPwGH/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQIBAT8Bp//EABkQAAMAAwAAAAAAAAAAAAAAAAABIRAiMf/aAAgBAQAGPwKsjZq4cFj/xAAaEAEAAgMBAAAAAAAAAAAAAAABABEhQVGR/9oACAEBAAE/ISgwBoisG1wj70o5NI8joEIYFT//2gAMAwEAAgADAAAAENDf/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAEDAQE/EMq//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/ENo//8QAHBABAQACAgMAAAAAAAAAAAAAAREAITFBUaGx/9oACAEBAAE/EHMgCkt75xxvgB5jv7rB7gEJZ6wrASdDJluvjIohbomf/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Visional\" title=\"\" src=\"/static/7dcdbba96ae2789a28d90c974627ddb4/1c72d/visional_cafe.jpg\" srcset=\"/static/7dcdbba96ae2789a28d90c974627ddb4/a80bd/visional_cafe.jpg 148w,\n/static/7dcdbba96ae2789a28d90c974627ddb4/1c91a/visional_cafe.jpg 295w,\n/static/7dcdbba96ae2789a28d90c974627ddb4/1c72d/visional_cafe.jpg 590w,\n/static/7dcdbba96ae2789a28d90c974627ddb4/a8a14/visional_cafe.jpg 885w,\n/static/7dcdbba96ae2789a28d90c974627ddb4/fbd2c/visional_cafe.jpg 1180w,\n/static/7dcdbba96ae2789a28d90c974627ddb4/3ec44/visional_cafe.jpg 1715w\" sizes=\"(max-width: 590px) 100vw, 590px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</p>\n<p>Established in April 2009, BizReach has been operating a variety of Internet services\nthat support the future of work in Japan with a mission that roughly translates into\n“creating a society where everyone can believe in their own potential”. The company,\nheadquartered in (Shibuya) Tokyo, has regional offices in Osaka, Nagoya, Fukuoka, Shizuoka, and Hiroshima.</p>\n<p>Visional was born in February 2020, when Bizreach Inc. shifted to a group management\nstructure. The company has continued its significant role in Japan’s HR Tech and\nSaaS sectors that promote digital transformation (DX) of industry and support the\nimprovement of productivity in Japan.</p>\n<blockquote>\n<p>Within the last 3 years, Visional Inc. was also listed on the Tokyo Stock Exchange.\nInitially listed on the TSE’s Mothers segment on April 22, 2021, Visional successfully\ntransitioned from the Growth Market segment to the Prime Market segment on December 14, 2023.\nThe company has demonstrated strong financial performance. As of late July 2024, Visional\nwas trading at a price around 9,370 JPY with a market cap of approximately 367.44 billion JPY.\nTheir P/E ratio stands around 24.66 and a significant profit growth of 53.2% YoY in FY2024 Q3​.</p>\n</blockquote>\n<p>Visional has strengthened its HR Tech segment, and platforms like BizReach and HRMOS\nare central to helping companies utilize human resources based on <strong>data-driven insights</strong>.\nThe incubation segment has also seen significant growth, focusing on developing new businesses\nin areas with high market potential, particularly in logistics and B2B services​.</p>\n<p>The group broadly has a heirarchical structure with the following products and services:</p>\n<blockquote>\n<p><a href=\"https://www.visional.inc/ja/index.html\">Visional Corporation</a>, the holding company, supports the group management</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.bizreach.co.jp/\">Bizreach Corporation</a>, responsible for the management of the original HR Tech and SaaS businesses</p>\n</blockquote>\n<ul>\n<li><a href=\"https://www.bizreach.jp/\">Bizreach</a>, a professional HR platform that connects companies with available talent</li>\n<li><a href=\"https://hrmos.co/hr\">HRMOS Talent Management</a>, an employee management platform</li>\n<li><a href=\"https://hrmos.co/ats\">HRMOS Recruitment</a>, an recruitment management system</li>\n<li><a href=\"https://hrmos.co/kintai\">HRMOS Attendance</a>, an attendance management system</li>\n<li><a href=\"https://www.ezsoft.co.jp/ekeihi/\">HRMOS Expenses</a>, an expense settlement system</li>\n<li><a href=\"https://hrmos.co/payroll\">HRMOS Payroll</a>, a payroll management system</li>\n<li><a href=\"https://br-campus.jp/\">Bizreach Campus</a>, an alumni network service for career consultation</li>\n</ul>\n<blockquote>\n<p><a href=\"https://www.visional.inc/ja/visional-incubation.html\">Visional Incubation Corporation</a>, responsible for new business development and acquisitions</p>\n</blockquote>\n<ul>\n<li><a href=\"https://ma-succeed.jp/\">M&#x26;A Succeed</a>, an M&#x26;A platform for business succession</li>\n<li><a href=\"https://yamory.io/\">Yamory</a>, security vulnerability management cloud for IT systems</li>\n<li><a href=\"https://www.trabox.ne.jp/\">Trabox</a>, a platform focused on digital transformation in the logistics industry</li>\n<li><a href=\"https://assured.jp/ja/\">Assured</a>, a cloud security risk assessment service</li>\n<li><a href=\"https://jp.stanby.com/\">StanBy</a>, a job-search engine jointly owned with Yahoo Japan</li>\n</ul>\n<p>Each of the products have their own specific engineering teams that follow custom\nAgile software development life cycles (SDLCs) they are comfortable with.</p>\n<p>The <strong>AI Team</strong> is a team of around 20 ML/AI engineers that collaborate with one or\nmore of the above mentioned products to understand their business requirements, and leverage\ndata to deploy AI features in production environments to drive business solutions.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n<h2 id=\"conclusion\">The Road Ahead</h2>\n<p>The last three years have not just been about professional growth; they have also been\nabout personal development. Adopting OKRs, improving my communication skills in a multilingual\nenvironment, and taking ownership of more complex projects have all contributed to a more\nholistic growth trajectory. I’ve learned to balance my technical expertise with strategic\nthinking, ensuring that I can contribute effectively both as an engineer and as a leader.</p>\n<p>As I look forward to the next phase of my career, I am excited about the possibilities that\nlie ahead. After a quarter of my life, I am well aware that I shall always be a Jack-of-all-Trades.\nWhether it’s further deepening my expertise in MLOps, taking on more leadership roles, or exploring new domains\nwithin LLM applications, I am confident that the foundation I’ve built over these five years will serve me well.</p>\n<p>Also, after all these years, I am happy that I can say <code class=\"language-text\">頑張りましたね！</code>, instead of my usual <code class=\"language-text\">eigo tabemasen..</code> lol.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n<p>This blog serves as a continuation of my reflection from three years ago. If you’re interested in understanding how it all began, feel free to check out <a href=\"/blog/2021-visional\">A Look Back at My First Full-Time Job</a>.</p>","frontmatter":{"title":"ML Engineer - 5 Years of Experience - Reflection","date":"October 01, 2024","description":"A deep dive into my career progression over the last 5 years at Visional Inc."}}},"pageContext":{"slug":"/blog/2024-visional/","previous":{"fields":{"slug":"/blog/2021-docker-basics/"},"frontmatter":{"title":"Docker Basics"}},"next":null}},"staticQueryHashes":["63159454"],"slicesMap":{}}